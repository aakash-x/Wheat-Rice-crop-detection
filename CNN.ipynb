{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 320 images belonging to 2 classes.\n",
      "epoch1\n",
      "Found 37 images belonging to 2 classes.\n",
      "epoch2\n",
      "Epoch 1/8\n",
      "40/40 [==============================] - 79s 2s/step - loss: 0.0811 - acc: 0.9859 - val_loss: 2.2516 - val_acc: 0.4906\n",
      "Epoch 2/8\n",
      "40/40 [==============================] - 53s 1s/step - loss: 0.0416 - acc: 0.9906 - val_loss: 1.0346 - val_acc: 0.4810\n",
      "Epoch 3/8\n",
      "40/40 [==============================] - 55s 1s/step - loss: 0.0241 - acc: 0.9906 - val_loss: 1.9181 - val_acc: 0.4811\n",
      "Epoch 4/8\n",
      "40/40 [==============================] - 119s 3s/step - loss: 0.0227 - acc: 0.9914 - val_loss: 3.8342 - val_acc: 0.4937\n",
      "Epoch 5/8\n",
      "40/40 [==============================] - 126s 3s/step - loss: 0.0410 - acc: 0.9906 - val_loss: 1.2829 - val_acc: 0.5000\n",
      "Epoch 6/8\n",
      "40/40 [==============================] - 959s 24s/step - loss: 0.0104 - acc: 0.9937 - val_loss: 2.3911 - val_acc: 0.4684\n",
      "Epoch 7/8\n",
      "40/40 [==============================] - 64s 2s/step - loss: 0.0085 - acc: 0.9984 - val_loss: 1.3495 - val_acc: 0.5943\n",
      "Epoch 8/8\n",
      "40/40 [==============================] - 67s 2s/step - loss: 0.0051 - acc: 0.9992 - val_loss: 1.8556 - val_acc: 0.5316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19e8b087c50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(activation=\"relu\", units=128))\n",
    "classifier.add(Dense(activation=\"sigmoid\", units=1))\n",
    "\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Part 2 - Fitting the CNN to the images\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('C:/Users/aakashX/Documents/CV Project/Training',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "print(\"epoch1\")\n",
    "test_set = test_datagen.flow_from_directory('C:/Users/aakashX/Documents/CV Project/Test',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "print(\"epoch2\")\n",
    "\n",
    "nb_train_samples = 800\n",
    "nb_validation_samples = 100\n",
    "epochs = 8\n",
    "batch_size = 20\n",
    "classifier.fit_generator(training_set,steps_per_epoch=nb_train_samples // batch_size,epochs=epochs,validation_data= test_set,validation_steps=nb_validation_samples // batch_size,\n",
    "                    workers=5,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wheat\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('C:/Users/aakashX/Documents/CV Project/wheat/N002.jpg',target_size = (64, 64))\n",
    "test_image =image.img_to_array(test_image)\n",
    "test_image =np.expand_dims(test_image,axis =0)\n",
    "result =classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0]>=0.5:\n",
    "    prediction ='wheat'\n",
    "else:\n",
    "    prediction='no'\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
